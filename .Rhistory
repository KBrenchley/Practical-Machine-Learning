sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2]
sumCoef[1,2]
fit
sumCoef
sumCoef[1,1]
sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2] * 1/2
sumCoef[2,1]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2] * 1/2
wt2 <- mtcars$wt / 2
newcars <- data.frame(mtcars$mpg, wt2)
names(newcars)
fit <- lm(mtcars.mpg ~ wt2, newcars)
fit
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
sumCoef
sumCoef[2,1]
sumCoef[2,2]
sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2]
sumCoef[2,1]
sumCoef[1,1]
(1 * 1000) / 2000
library(swirl)
swirl()
fit <- lm(y ~ x, out2)
plot(fit, which = 1)
fitno <- lm(y ~ x, out2[-1, ]
)
plot(fitno, which = 1)
coef(fit) - coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- sqrt(fit$deviance/fit$df)
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- resid(fit)/sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma*sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which = 3)
plot(fit, which = 2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/(sigma1 * sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy <- predict(fitno, out2) - predict(fit, out2)
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ ., data = swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ . - Examination, data = swiss)
vif(mdl2)
data(mtcars)
head(mtcars)
lm(mpg ~ cyl + wt, mtcars)
lm(mpg ~ cyl * wt, mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df <- data.frame(x,y)
df
fit <- lm(y ~ x, df)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
df <- data.frame(x,y)
fit <- lm(y ~ x, df)
?influence.measures
dfbetas(fit)[5,]
fit <- lm(mpg ~ cyl + wt)
fit <- lm(mpg ~ cyl + wt, mtcars)
summary(fit)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
fit
fit2 <- lm(mpg ~ factor(cyl))
fit2 <- lm(mpg ~ factor(cyl), mtcars)
fit2
fit3 <- lm(mpg ~ factor(cyl) * wt, mtcars)
fit3
anova(fit, fit3)
fit4 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
fit4
anova(fit, fit3)
library(swirl)
swirl()
x1c <- simbias
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail = FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, family = "Binomial", ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family = "binomial", ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1 + exp(lodds))
summary(mdl)
exp(confint(mdl))/(1 + exp(confint(mdl)))
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
nxt()
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, family = "poisson", hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(visits ~ date + simplystats, family = "poisson", hits, offset=log(visits+1))
mdl2 <- glm(simplystats ~ date, family = "poisson", hits, offset=log(visits+1))
qpois(.95,mdl2$fitted.values[704])
?shuttle
6/15
1/6 * 15
library(MASS)
data(shuttle)
head(shuttle)
fit <- glm(use ~ wind, data = shuttle, family = "binomial")
summary(fit)
exp(fit$coeff)
fit2 <- glm(use ~ wind + magn, data = shuttle, family = "binomial")
exp(fit2$coeff)
fit3 <- glm(I(1-use) ~ wind , data = shuttle, family = "binomial")
data(IndextSprays)
data(InsectSprays)
head(InsectSprays)
fit4 <- glm(count ~ factor(spray), data = InsectSprays, family = "poisson")
summary(fit4)
2.67415/0.05588
exp(2.67415)/exp(0.05588)
swirl()
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~date, interval = "poisson", hits)
mdl <- glm(visits ~date, family = "poisson", data =hits)
summary(mdl)
exp(confint(mdl, 'date'))
exit
quit
fit4
exp(2.67415/0.05588)
exp(confit(ft4))
exp(confint(fit4))
12.4508255/0.8595374
16.7623971/1.3015071
summary(fit4)
409.041/98.329
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
summary(fit2)
exp(fit2$coeff)
fit1
fit
fit4
count <- c(8, 4, 5, 12, 3, 1, 1, 17)
x <- c(1, 1, 0, 1, 0, 1, 1, 0)
df <- data.frame(x, count)
?log
t <- c(3, 9, 7, 6, 3, 13, 4, 4)
t <- log(t)
t2 <- log(10)
fit5a <- glm(count ~ x + offset(t), family = poisson, df)
fit5b <- glm(count ~ x + offset(t2), family = poisson, df)
t2 <- log(10) + t
fit5b <- glm(count ~ x + offset(t2), family = poisson, df)
summary(fit5a)
summary(fit5b)
exp(fit5a$coeff)
exp(fit5b$coeff)
fit5a$coeff
fit5b$coeff
fit4
data(InsectSprays)
names(InsectSprays)
str(InsectSprays)
head(InsectSprays)
fit <- glm(count ~ spray, InsectSprays)
fit <- glm(count ~ spray, InsectSprays, family = "poisson")
summary(fit)
sB <- 0.05588
sA <- 2.67415
sA/sB
sA / (1 + sB)
exp(sA)/exp(sB)
exp(sB)/exp(sA)
sB/sA
log(sA)/log(sB)
log(sB)/log(sA)
?relevel
names(InsectSprays)
InsectSprays$spray2 <- relevel(InsectSprays$spray, ref="A")
head(InsectSprays)
InsectSprays$spray2 <- relevel(InsectSprays$spray, ref="B")
head(InsectSprays)
str(InsectSprays)
fit2 <- glm(count ~ spray2, InsectSprays, family = "poisson")
summary(fit2)
summary(fit)
sA2 <- - sB
sB2 <- SA
sB2 <- sA
sA2
sB2
sA2/sB2
exp(sA2)/expsB2)
exp(sA2)/exp(sB2)
1/sB2
1/sA2
1/exp(sB2)
1/exp(sA2)
1/(sB/sA)
sA/sB
Q4.1 <- 0.136
Q4.2 <- .9457
sA/Q4.1
sA/Q4.2
sA2/Q4.1
sA2/Q4.2
sA2(1 + sB2)
sA2/(1 + sB2)
sA2/(1 - sB2)
exp(sA2)/(1 + exp(sB2))
exp(sA2)/(1 - exp(sB2))
exp(sB2)/(1 - exp(sA2))
exp(sB2)/(1 + exp(sA2))
exp(sB)
exp(sA)
9/40
40/9
?xyplot
??xyplot
install.packages("xyplot")
library(lattice)
?xyplot
install.packages("caret")
install.packages("~/Downloads/caret_6.0-41.tgz", repos = NULL)
install.packages("~/Downloads/BradleyTerry2_1.0-5.tgz", repos = NULL)
install.packages("~/Downloads/brglm_0.5-9.tgz", repos = NULL)
install.packages("~/Downloads/foreach_1.4.2.tgz", repos = NULL)
install.packages("~/Downloads/gtools_3.4.1.tgz", repos = NULL)
install.packages("~/Downloads/iterators_1.0.7.tgz", repos = NULL)
install.packages("~/Downloads/lme4_1.1-7.tgz", repos = NULL)
install.packages("~/Downloads/minqa_1.2.4.tgz", repos = NULL)
install.packages("~/Downloads/nloptr_1.0.4.tgz", repos = NULL)
install.packages("~/Downloads/profileModel_0.5-9.tgz", repos = NULL)
load(caret)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("~/Downloads/AppliedPredictiveModeling_1.1-6.tgz", repos = NULL)
install.packages("~/Downloads/CORElearn_0.9.44.tgz", repos = NULL)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
dim(diagnosis)
head(diagnosis)
head(predictors)
head(diagnosis)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
forget test
forget(test)
ignore(test)
remove(test)
remove(train)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
q1.2.training <- training
q1.2.testing <- testing
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
trainIndex = createDataPartition(diagnosis, p = 0.50)
data(concrete)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, pch = 19)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, color = training$Cement)
plot(training$CompressiveStrength, col = training$Cement)
qplot(training$CompressiveStrength, colour = training$Cement)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, training$Cement)
plot(training$CompressiveStrength, training$Cement, col=training$Cement)
library(Hmisc)
str(training)
?cut2
CementCut <- cut2(training$Cement, g = 5)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, col = CementCut)
CementCut <- cut2(training$Cement, g = 3)
plot(training$CompressiveStrength, col = CementCut)
CementCut
table(CementCut)
range(training$Cement)
plot(CementCut, training$CompressiveStrength)
qplot(CementCut, training$CompressiveStrength)
qplot(training$CompressiveStrength)
qplot(training$CompressiveStrength, colour = CementCut)
plot(training$CompressiveStrength ~ Index)
plot(training$CompressiveStrength, col = ConcreteCut)
plot(training$CompressiveStrength, col = CementCut)
plot(training$CompressiveStrength, col = training$BlastFurnaceSlag)
BlastCut <- cut2(training$BlastFurnaceSlag, g =3)
plot(training$CompressiveStrength, col = BlastCut)
FlyAshCut <- cut2(training$FlyAsh, g = 4)
plot(training$CompressiveStrength, col = FlyAshCut)
WaterCut <- cut2(training$Water, g = 6)
plot(training$CompressiveStrength, col = WaterCut)
SuperCut <- cut2(training$Superplasticizer, g = 3)
plot(training$CompressiveStrength, col = SuperCut)
AgeCut <- cut2(training$Age, g = 3)
plot(training$CompressiveStrength, col = AgeCut)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
SuperLog <- log10(training$Superplasticizer)
hist(SuperLog)
range(training$Superplasticizer)
log10(0)
boxplot(training$Superplasticizer)
boxplot(SuperLog)
range(SuperLog)
SuperLogPlus <- log10(training$Superplasticizer + 1)
range(SuperLogPlus)
str(SuperLogPlus)
mean(SuperLogPlus)
median(SuperLogPlus)
hist(SuperLogPlus)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?preProcess
trainingIL <- select(training, starts_with('IL'))
trainingIL <- subset(training, select = starts_with('IL'))
trainingIL <- subset(training, select = grep("IL"))
trainingIL <- subset(training, select = grep("IL", training[,1-131]))
trainingIL
trainingIL[1]
grep("IL" names(training))
grep("IL", names(training))
grep("^IL", names(training))
preProcess(training[,58-59], method = "pca", thresh = .80)
training[,58-69]
names(training[,58-69])
training[,58]
library(dplyr)
trainingIL = select(training, starts_with('IL'))
names(trainingIL)
preProcess(training[,58-59], method = "pca", thresh = .80)
str(trainingIL)
preProcess(trainingIL, method = "pca", thresh = .80)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(dplyr)
trainingIL = select(training, starts_with('IL'))
trainingIL <- cbind(trainingIL, diagnosis)
dim(trainingIL)
dim(diagnosis)
length(diagnosis)
dim(adData)
trainingIL <- cbind(trainingIL, training$diagnosis)
head(trainingIL)
dim(trainingIL)
preP <- preProcess(trainingIL[,-13], method="rca", thresh = .80
)
preP <- preProcess(trainingIL[,-13], method="pca", thresh = .80)
preP
head(trainingIL)
heads <- head(trainingIL)
heads
names <- names(trainingIL)
names
names[13] <- "diagnosis"
names
names(trainingIL) <- names
names(trainingIL)
plain.fit <- train(diagnosis ~ ., data = trainingIL, method ="glm")
install.packages("e1071", dep = TRUE, type = "source")
plain.fit <- train(diagnosis ~ ., data = trainingIL, method ="glm")
install.packages("e1071")
install.packages("~/Downloads/e1071_1.6-4.tar.gz", repos = NULL, type = "source")
plain.fit <- train(diagnosis ~ ., data = trainingIL, method ="glm")
preP
PCA.fit <- training(preP, trainingIL[,-13])
PCA.fit <- train(preP, trainingIL[,-13])
PCA.fit <- train(preP, trainingIL[,-13])
trainingIL[,-13]
names(trainingIL[,-13])
preP
PCA.fit <- train(preP, trainingIL[,-13])$diagnosis
plain.fit
preP
plain.fit$finalModel
plain.predictions <- predict(plain.fit, newdata = testing)
confusionMatrix(plain.predictions, testing$diagnosis)
preP <- preProcess(trainingIL[,-13], method="pca", thresh.80)
preP <- preProcess(trainingIL[,-13], method="pca", thresh=.80)
PCA.predict <- predict(preP, trainingIL[,-13])
PCA.predict <- predict(preP, trainingIL[,-13])
PCA.predict <- predict(preP, testing[,-1])
library(dplyr)
testingIL = select(testing, starts_with('IL'))
testingIL <- rbind(testingIL, testing$diagnosis)
names(testingIL)
test.names <- names(testingIL)
RCA.predict <- predict(preP, testing)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
library(caret)
set.seed(11854)
setwd("~/Documents/Coursera/Practical Machine Learning/Project/Practical-Machine-Learning")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
library(caret)
set.seed(11854)
near.zero <- nearZeroVar(training,saveMetrics = TRUE)
training.new <- training[,near.zero$nzv == FALSE]
training.new <- training.new[colSums(is.na(training.new)) == 0]
train.folds <- createFolds(y = training.new$classe, k=10, list=TRUE, returnTrain=TRUE)
test.folds <- createFolds(y = training.new$classe, k=10, list=TRUE, returnTrain=FALSE)
sapply(train.folds, length)
sapply(test.folds, length)
train.set1 <- train.folds[[1]]
train1 <- training.new[train.set1,]
test.set1 <- test.folds[[1]]
test1 <- training[test.set1,]
train1$cvtd_timestamp <-  as.numeric(train1$cvtd_timestamp)
train1$user_name <- as.numeric(train1$user_name)
len <- length(test1$classe)
test1$classe <- NULL
test1$problem_id <- 1:len
test1$cvtd_timestamp <-  as.numeric(test1$cvtd_timestamp)
test1$user_name <- as.numeric(test1$user_name)
M <- abs(cor(train1[,-59]))
diag(M) <- 0
cor.pred <- which(M > 0.8, arr.ind=T)
cor.pred
train1.small <- train1[,c(2, 5, 7, 8, 9, 10, 14, 15, 16, 17, 24, 25, 27, 30, 31, 32, 34, 35, 37, 39, 40, 42, 51, 52)]
train1.small$classe <- train1$classe
str(train1.small)
fit1.small <- train(classe ~ ., data = train1.small, method = "glm")
train1.small$classe <- to.character(train1.small$classe)
train1.small$classe <- as.character(train1.small$classe)
str(train1.small)
fit1.small <- train(classe ~ ., data = train1.small, method = "glm")
warnings()
train1.small$classe <- train1$classe
class(train1$classe)
fit1.small <- train(classe ~ ., data = train1.small, metric = "Accuray", method = "glm")
fit.temp <- train(classe ~ roll_belt, data=train1.small, method = "glm")
fit.temp <- train(classe ~ roll_belt, data=training, method = "glm")
training<- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
download.fil(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="pml-training.csv",method="curl")
download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="pml-training.csv",method="curl")
training <- read.csv("pml-training.csv")
near.zero <- nearZeroVar(training,saveMetrics = TRUE)
training.new <- training[,near.zero$nzv == FALSE]
## and get rid of the ones that are mostly NA
training.new <- training.new[colSums(is.na(training.new)) == 0]
## make new training sets based on training.new
train.folds <- createFolds(y = training.new$classe, k=10, list=TRUE, returnTrain=TRUE)
train.set1 <- train.folds[[1]]
train1 <- training.new[train.set1,]
train1$cvtd_timestamp <-  as.numeric(train1$cvtd_timestamp)
train1$user_name <- as.numeric(train1$user_name)
len <- length(test1$classe)
test1$classe <- NULL
test1$problem_id <- 1:len
test1$cvtd_timestamp <-  as.numeric(test1$cvtd_timestamp)
test1$user_name <- as.numeric(test1$user_name)
