exp(2.67415/0.05588)
exp(confit(ft4))
exp(confint(fit4))
12.4508255/0.8595374
16.7623971/1.3015071
summary(fit4)
409.041/98.329
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
summary(fit2)
exp(fit2$coeff)
fit1
fit
fit4
count <- c(8, 4, 5, 12, 3, 1, 1, 17)
x <- c(1, 1, 0, 1, 0, 1, 1, 0)
df <- data.frame(x, count)
?log
t <- c(3, 9, 7, 6, 3, 13, 4, 4)
t <- log(t)
t2 <- log(10)
fit5a <- glm(count ~ x + offset(t), family = poisson, df)
fit5b <- glm(count ~ x + offset(t2), family = poisson, df)
t2 <- log(10) + t
fit5b <- glm(count ~ x + offset(t2), family = poisson, df)
summary(fit5a)
summary(fit5b)
exp(fit5a$coeff)
exp(fit5b$coeff)
fit5a$coeff
fit5b$coeff
fit4
data(InsectSprays)
names(InsectSprays)
str(InsectSprays)
head(InsectSprays)
fit <- glm(count ~ spray, InsectSprays)
fit <- glm(count ~ spray, InsectSprays, family = "poisson")
summary(fit)
sB <- 0.05588
sA <- 2.67415
sA/sB
sA / (1 + sB)
exp(sA)/exp(sB)
exp(sB)/exp(sA)
sB/sA
log(sA)/log(sB)
log(sB)/log(sA)
?relevel
names(InsectSprays)
InsectSprays$spray2 <- relevel(InsectSprays$spray, ref="A")
head(InsectSprays)
InsectSprays$spray2 <- relevel(InsectSprays$spray, ref="B")
head(InsectSprays)
str(InsectSprays)
fit2 <- glm(count ~ spray2, InsectSprays, family = "poisson")
summary(fit2)
summary(fit)
sA2 <- - sB
sB2 <- SA
sB2 <- sA
sA2
sB2
sA2/sB2
exp(sA2)/expsB2)
exp(sA2)/exp(sB2)
1/sB2
1/sA2
1/exp(sB2)
1/exp(sA2)
1/(sB/sA)
sA/sB
Q4.1 <- 0.136
Q4.2 <- .9457
sA/Q4.1
sA/Q4.2
sA2/Q4.1
sA2/Q4.2
sA2(1 + sB2)
sA2/(1 + sB2)
sA2/(1 - sB2)
exp(sA2)/(1 + exp(sB2))
exp(sA2)/(1 - exp(sB2))
exp(sB2)/(1 - exp(sA2))
exp(sB2)/(1 + exp(sA2))
exp(sB)
exp(sA)
9/40
40/9
?xyplot
??xyplot
install.packages("xyplot")
library(lattice)
?xyplot
install.packages("caret")
install.packages("~/Downloads/caret_6.0-41.tgz", repos = NULL)
install.packages("~/Downloads/BradleyTerry2_1.0-5.tgz", repos = NULL)
install.packages("~/Downloads/brglm_0.5-9.tgz", repos = NULL)
install.packages("~/Downloads/foreach_1.4.2.tgz", repos = NULL)
install.packages("~/Downloads/gtools_3.4.1.tgz", repos = NULL)
install.packages("~/Downloads/iterators_1.0.7.tgz", repos = NULL)
install.packages("~/Downloads/lme4_1.1-7.tgz", repos = NULL)
install.packages("~/Downloads/minqa_1.2.4.tgz", repos = NULL)
install.packages("~/Downloads/nloptr_1.0.4.tgz", repos = NULL)
install.packages("~/Downloads/profileModel_0.5-9.tgz", repos = NULL)
load(caret)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("~/Downloads/AppliedPredictiveModeling_1.1-6.tgz", repos = NULL)
install.packages("~/Downloads/CORElearn_0.9.44.tgz", repos = NULL)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
dim(diagnosis)
head(diagnosis)
head(predictors)
head(diagnosis)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
forget test
forget(test)
ignore(test)
remove(test)
remove(train)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
q1.2.training <- training
q1.2.testing <- testing
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
trainIndex = createDataPartition(diagnosis, p = 0.50)
data(concrete)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, pch = 19)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, color = training$Cement)
plot(training$CompressiveStrength, col = training$Cement)
qplot(training$CompressiveStrength, colour = training$Cement)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, training$Cement)
plot(training$CompressiveStrength, training$Cement, col=training$Cement)
library(Hmisc)
str(training)
?cut2
CementCut <- cut2(training$Cement, g = 5)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength, col = CementCut)
CementCut <- cut2(training$Cement, g = 3)
plot(training$CompressiveStrength, col = CementCut)
CementCut
table(CementCut)
range(training$Cement)
plot(CementCut, training$CompressiveStrength)
qplot(CementCut, training$CompressiveStrength)
qplot(training$CompressiveStrength)
qplot(training$CompressiveStrength, colour = CementCut)
plot(training$CompressiveStrength ~ Index)
plot(training$CompressiveStrength, col = ConcreteCut)
plot(training$CompressiveStrength, col = CementCut)
plot(training$CompressiveStrength, col = training$BlastFurnaceSlag)
BlastCut <- cut2(training$BlastFurnaceSlag, g =3)
plot(training$CompressiveStrength, col = BlastCut)
FlyAshCut <- cut2(training$FlyAsh, g = 4)
plot(training$CompressiveStrength, col = FlyAshCut)
WaterCut <- cut2(training$Water, g = 6)
plot(training$CompressiveStrength, col = WaterCut)
SuperCut <- cut2(training$Superplasticizer, g = 3)
plot(training$CompressiveStrength, col = SuperCut)
AgeCut <- cut2(training$Age, g = 3)
plot(training$CompressiveStrength, col = AgeCut)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
SuperLog <- log10(training$Superplasticizer)
hist(SuperLog)
range(training$Superplasticizer)
log10(0)
boxplot(training$Superplasticizer)
boxplot(SuperLog)
range(SuperLog)
SuperLogPlus <- log10(training$Superplasticizer + 1)
range(SuperLogPlus)
str(SuperLogPlus)
mean(SuperLogPlus)
median(SuperLogPlus)
hist(SuperLogPlus)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?preProcess
trainingIL <- select(training, starts_with('IL'))
trainingIL <- subset(training, select = starts_with('IL'))
trainingIL <- subset(training, select = grep("IL"))
trainingIL <- subset(training, select = grep("IL", training[,1-131]))
trainingIL
trainingIL[1]
grep("IL" names(training))
grep("IL", names(training))
grep("^IL", names(training))
preProcess(training[,58-59], method = "pca", thresh = .80)
training[,58-69]
names(training[,58-69])
training[,58]
library(dplyr)
trainingIL = select(training, starts_with('IL'))
names(trainingIL)
preProcess(training[,58-59], method = "pca", thresh = .80)
str(trainingIL)
preProcess(trainingIL, method = "pca", thresh = .80)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(dplyr)
trainingIL = select(training, starts_with('IL'))
trainingIL <- cbind(trainingIL, diagnosis)
dim(trainingIL)
dim(diagnosis)
length(diagnosis)
dim(adData)
trainingIL <- cbind(trainingIL, training$diagnosis)
head(trainingIL)
dim(trainingIL)
preP <- preProcess(trainingIL[,-13], method="rca", thresh = .80
)
preP <- preProcess(trainingIL[,-13], method="pca", thresh = .80)
preP
head(trainingIL)
heads <- head(trainingIL)
heads
names <- names(trainingIL)
names
names[13] <- "diagnosis"
names
names(trainingIL) <- names
names(trainingIL)
plain.fit <- train(diagnosis ~ ., data = trainingIL, method ="glm")
install.packages("e1071", dep = TRUE, type = "source")
plain.fit <- train(diagnosis ~ ., data = trainingIL, method ="glm")
install.packages("e1071")
install.packages("~/Downloads/e1071_1.6-4.tar.gz", repos = NULL, type = "source")
plain.fit <- train(diagnosis ~ ., data = trainingIL, method ="glm")
preP
PCA.fit <- training(preP, trainingIL[,-13])
PCA.fit <- train(preP, trainingIL[,-13])
PCA.fit <- train(preP, trainingIL[,-13])
trainingIL[,-13]
names(trainingIL[,-13])
preP
PCA.fit <- train(preP, trainingIL[,-13])$diagnosis
plain.fit
preP
plain.fit$finalModel
plain.predictions <- predict(plain.fit, newdata = testing)
confusionMatrix(plain.predictions, testing$diagnosis)
preP <- preProcess(trainingIL[,-13], method="pca", thresh.80)
preP <- preProcess(trainingIL[,-13], method="pca", thresh=.80)
PCA.predict <- predict(preP, trainingIL[,-13])
PCA.predict <- predict(preP, trainingIL[,-13])
PCA.predict <- predict(preP, testing[,-1])
library(dplyr)
testingIL = select(testing, starts_with('IL'))
testingIL <- rbind(testingIL, testing$diagnosis)
names(testingIL)
test.names <- names(testingIL)
RCA.predict <- predict(preP, testing)
loess
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
unique(training$Case)
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
dim(training)
dim(testing)
set.seed(125)
fit <- train(Class ~ . - Case, data = training, method = "rpart")
fit
print(fit)
plot(fit$finalModel, uniform = TRUE)
test(fit$finalModel, use.n = TRUE, all = TRUE, ces=.8)
text(fit$finalModel, use.n = TRUE, all = TRUE, ces=.8)
library(rattle)
install.packages("rattle")
install.packages("~/Downloads/rattle_3.4.1.tgz", repos = NULL)
library(rattle)
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
install.packages("~/Downloads/rpart.plot_1.5.1.tgz", repos = NULL)
fancyRpartPlot(fit$finalModel)
options(scipen = 999)
fancyRpartPlot(fit$finalModel)
45e+3
fit2 <- train(Class ~ ., data = training, method = "rpart")
print(fit$finalModel)
print(fit2$finalModel)
S <- segmentationOriginal
S2 <- data.frame(S$TotalIntench2, S$FiberWidthCh1, S$PerimStatusCh1, S$VarIntenCh)
length(S$TotalIntenCh2)
S2 <- data.frame(S$TotalIntenCh2, S$FiberWidthCh1, S$PerimStatusCh1, S$VarIntenCh)
S$FiberWidthCh1
S2 <- data.frame(S$TotalIntenCh2, S$FiberWidthCh1, S$PerimStatusCh1, S$VarIntenCh)
S$PerimStatusCh1
S2 <- data.frame(S$TotalIntenCh2, S$FiberWidthCh1, S$PerimStatusCh1, S$VarIntenCh)
S2 <- data.frame(S$TotalIntenCh2, S$FiberWidthCh1, S$PerimStatusCh1, S$VarIntenCh4)
S2 <- data.frame(TotalIntenCh2 = c(23000,50000,57000,0), FiberWidthCh1 = c(10,10,8,8), PerimStatusCh1 = c(2, 0, 0 2), VarIntenCh4=c(0,100,100,100))
S2 <- data.frame(TotalIntenCh2 = c(23000,50000,57000,0), FiberWidthCh1 = c(10,10,8,8), PerimStatusCh1 = c(2, 0, 0 2), VarIntenCh4=c(0,100,100,100))
S3 <- data.frame(TotalIntenCh2 = c(23000,50000,57000,0),
FiberWidthCh1 = c(10,10,8,8),
PerimStatusCh1 = c(2, 0, 0 2),
VarIntenCh4 =c (0,100,100,100))
S3 <- data.frame(TotalIntenCh2 = c(23000,50000,57000,0),
FiberWidthCh1 = c(10,10,8,8),
PerimStatusCh1 = c(2, 0, 0,2),
VarIntenCh4 =c (0,100,100,100))
predict(fit, data = S3)
print(fit$finalModel)
S3 <- S[1:4]
S3$TotalIntenCh1 <- c(23000,50000,57000,0)
dim(S3)
S3 <- S[1:4,]
dim(S3)
S3$TotalIntenCh1 <- c(23000,50000,57000,0)
S3$FiberWidthCh1 <- c(10,10,8,8)
S3$PerimStatusCh1 <- c(2,0,0,2)
S3$VarIntenCh4 <- c(0,100,100,0)
predict(fit2, newdata = S3)
predict(fit, newdata = S3)
q3.2 <- data.frame(a = 1:4, b = c("m","a","r","y"), c = c("Patch","Phantom","Mac","Barry"))
q3.2
folds1 <- createFolds(y=q3.2$b, k=1, list=TRUE, returnTrain=TRUE)
folds1
q3.2$d <- c(0,0,1,0)
row5 <- c(5,"e","Leo",1)
row6 <- c(6,"l","Teddy",0)
q3.2 <- rbind(q3.2,row5)
q3.2
q3.2[5,b] <- "e"
q3.2$b[5] <- "e"
str(q3.2)
q3.2 <- as.character(q3.2$b)
q3.2 <- as.character(q3.2$c)
row5
str(q3.2)
q3.2 <- data.frame(a = 1:10,
b = c("m","a","r","y", "e","l","l","e","n","w"),
c = c("Patch","Phantom","Mac","Barry", "Fang","Barry","Mac", "Leo","Patch","Patch")
d = c(1, 0, 1, 1,0,0,1,1,0,1)
)
q3.2 <- data.frame(a = 1:10,
b = c("m","a","r","y", "e","l","l","e","n","w"),
c = c("Patch","Phantom","Mac","Barry", "Fang","Barry",
"Mac", "Leo","Patch","Patch"),
d = c(1, 0, 1, 1,0,0,1,1,0,1)
)
q3.2
str(q3.2)
createFolds(y=q3.2$d, k=1, returnTrain = TRUE)
train.folds <-createFolds(y=q3.2$d, k=1, returnTrain = TRUE)
sapply(train.folds,length)
train.folds <-createFolds(y=q3.2$c, k=1, returnTrain = TRUE)
sapply(train.folds,length)
library(pgmm)
data(olive)
olive = olive[,-1]
fit <- train(Area ~ ., method = "rpart", data=olive)
library(caret)
fit <- train(Area ~ ., method = "rpart", data=olive)
print(fit$finalModal)
colSum(olive)
sumCol(olive)
?olive
fit <- train(Area ~ ., method = "tree", data=olive)
?tree
install.packages("tree")
install.packages("~/Downloads/tree_1.0-35.tgz", repos = NULL)
?tree
package(tree)
library(tree)
?tree
fit <- tree(Area ~ ., olive)
fit
plot(fit)
newdata = as.data.frame(t(colMeans(olive)))
predict(fit, newdata = newdadta)
predict(fit, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("~/Downloads/ElemStatLearn_2012.04-0.tgz", repos = NULL)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
?SAheart
fit <- train(chd ~  age + alcohol + obesity + tobacco + typea + ldl  ,
data <- tainSA,method = "glm", family="binomial")
library(caret)
fit <- train(chd ~  age + alcohol + obesity + tobacco + typea + ldl  ,
data <- tainSA,method = "glm", family="binomial")
fit <- train(chd ~  age + alcohol + obesity + tobacco + typea + ldl  ,
data <- SAheart,method = "glm", family="binomial")
summary(fit)
str(trainSA)
fit <- train(chd ~  age + alcohol + obesity + tobacco + typea + ldl  ,
data <- trainSA,method = "glm", family="binomial")
summary(fit)
pred <- predict(fit,testSA)
pred
testMiss <- missClass(pred,testSA)
testMiss <- missClass(testSA, pred)
testMiss
testMiss <- missClass(testSA$chd, pred)
testMiss
trainMiss <- missClass(trainSA$chd, pred)
trainMiss
pred2 <- predict(fit, trainSA)
trainMiss <- missClass(trainSA$chd, pred2)
trainMiss
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.test)
str(vowel.train)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
fit <- train(y ~ ., method = "rf", data = vowel.train)
library(caret)
fit <- train(y ~ ., method = "rf", data = vowel.train)
summary(fit)
plot(fit$finalModel)
?varImp
varImp(fit,useModel = TRUE, nonpara=TRUE, scale = TRUE)
?randomForest
fit <- randomForest(y ~ ., data = vowel.train)
varImp(fit,useModel = TRUE, nonpara=TRUE, scale = TRUE)
fit <- randomForest(y ~ ., data = vowel.train, importance = TRUE, proximity = TRUE)
varImp(fit,useModel = TRUE, nonpara=TRUE, scale = TRUE)
?nrows
?nrow
setwd("~/Documents/Coursera/Practical Machine Learning/Project/Practical-Machine-Learning")
##download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="pml-training.csv",method="curl")
##download.file(url="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfil="pml-testing.csv",method = "curl")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
library(caret)
library(randomForest)
library(tree)
library(rpart)
library(gbm)
library(survival)
library(splines)
library(plyr)
set.seed(11854)
near.zero <- nearZeroVar(training,saveMetrics = TRUE)
training.new <- training[,near.zero$nzv == FALSE]
## and get rid of the ones that are mostly NA
training.NA <- training.new[colSums(is.na(training.new)) > 0]
training.new <- training.new[colSums(is.na(training.new)) == 0]
train.folds <- createFolds(y = training.new$classe, k=10, list=TRUE, returnTrain=TRUE)
test.folds <- createFolds(y = training.new$classe, k=10, list=TRUE, returnTrain=FALSE)
## sapply(train.folds, length)
## sapply(test.folds, length)
train.set1 <- train.folds[[1]]
train1 <- training.new[train.set1,]
test.set1 <- test.folds[[1]]
test1 <- training[test.set1,]
## fix K-fold testing set so it can be predicted on (remove answers)
len <- length(test1$classe)
test1$classe <- NULL
test1$problem_id <- 1:len
length(train1)
length(train1$classe)
length(test1$classe)
names(test1)
length(test1$problem_id)
